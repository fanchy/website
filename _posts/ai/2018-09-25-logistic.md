---
layout: post
title:  logistic逻辑回归公式推导及R语言实现
categories: ai
tagline: Logistic逻辑回归拟合的是正类和负类的对数几率。
tags:
    - python
    - ai
    - R语言
    - Logistic
    - Logistic逻辑回归
excerpt: >
    线性回归模型简单，对于一些线性可分的场景还是简单易用的。Logistic逻辑回归也可以看成线性回归的变种，
    虽然名字带回归二字但实际上他主要用来二分类，区别于线性回归直接拟合目标值，
    Logistic逻辑回归拟合的是正类和负类的对数几率。
---
# Logistic逻辑回归
## Logistic逻辑回归模型
线性回归模型简单，对于一些线性可分的场景还是简单易用的。Logistic逻辑回归也可以看成线性回归的变种，虽然名字带回归二字但实际上他主要用来二分类，区别于线性回归直接拟合目标值，Logistic逻辑回归拟合的是正类和负类的对数几率。

假设有一个二分类问题，输出为y∈{0,1}

定义sigmoid函数: ![](/assets/img/logistic/logistic1.png)

用sigmoid函数的输出是0，1之间，用来拟合y=1的概率，其函数R语言画图如下：
```R
x = seq(-5, 5, 0.1)
y = 1 / (1 + exp(-1*x))
plot(x, y, type="line")
```
![](/assets/img/logistic/logistic2.png)

logistic逻辑回归可以拟合因变量为1的概率,最终分类的时候，我们可以一个阈值，比如0.5，大于阈值的都分为正类，向量化公式如下：

![](/assets/img/logistic/logistic3.png)


还可以换一种方式理解logistic逻辑回归，他是用多元线性函数去拟合因变量为正例与反例的比值的自然对数，推导如下：

![](/assets/img/logistic/logistic4.png)


![](/assets/img/logistic/logistic5.png)


## Logistic逻辑回归算法
- 假设自变量维度为N
- W为自变量的系数，下标0 - N
- X为自变量向量或矩阵，X维度为N,为了能和W0对应，X需要在第一行插入一个全是1的列。
- Y为因变量
- W为未知数待求解

### 最大似然估计法
![](/assets/img/logistic/logistic6.png)


### 梯度下降法迭代公式
![](/assets/img/logistic/logistic7.png)


## R语言实现
使用iris数据集
```R
> head(iris)
  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1          5.1         3.5          1.4         0.2  setosa
2          4.9         3.0          1.4         0.2  setosa
3          4.7         3.2          1.3         0.2  setosa
4          4.6         3.1          1.5         0.2  setosa
5          5.0         3.6          1.4         0.2  setosa
6          5.4         3.9          1.7         0.4  setosa
```
将数据分为训练数据和测试数据

R语言使用批量梯度下降法迭代求解
```R
iris2 = rbind(subset(iris, Species=='setosa'), subset(iris, Species=='versicolor'))
X <- cbind(rep(1, nrow(iris2)), iris2$Sepal.Length, iris2$Sepal.Width, iris2$Petal.Length, iris2$Petal.Width)
Y <- as.numeric(iris2$Species) - 1
maxIterNum <- 2000;
step <- 0.05;
W <- rep(0, ncol(X))
m = nrow(X)
sigmoid <- function(z) { 1 / (1 + exp(-z))}
for (i in 1:maxIterNum){
    grad <- t(X) %*% (sigmoid(X %*% W)-Y);
    if (sqrt(as.numeric(t(grad) %*% grad)) < 1e-8){
        print(sprintf('iter times=%d', i));
        break;
    }
    W <- W - grad * step;
}
print(W);
hfunc <- function(a) {if (a > 0.5) return(1) else return (0);}
myY = apply(sigmoid(X %*% W), 1, hfunc)
print(cbind(Y, myY))
```
输出后，可以看到拟合完全正确，因为本文只是为了推导一下逻辑回归的算法，所以直接用全部数据拟合，没有再抽出一部分做测试数据。

## 总结
- 应该增加一部分训练数据，验证模型的正确性
- 应该增加正则项避免过拟合，比如L2正则

更多精彩文章 [http://h2cloud.org/](http://h2cloud.org/)